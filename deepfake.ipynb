{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing all the necessary packages\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import torchaudio\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import tqdm\n",
    "import PIL\n",
    "import sklearn\n",
    "import streamlit\n",
    "\n",
    "print(\"✅ All packages are imported successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load and Preprocess Dataset \n",
    "import torch\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Define image transformations\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),  # Resize images to 224x224 for ResNet50\n",
    "    transforms.ToTensor(),          # Convert images to tensors\n",
    "    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])  # Normalize\n",
    "])\n",
    "\n",
    "# Define dataset paths\n",
    "data_dir = r\"D:\\Projects\\Dataset\"\n",
    "\n",
    "# Load datasets\n",
    "train_dataset = datasets.ImageFolder(root=f\"{data_dir}/Train\", transform=transform)\n",
    "val_dataset = datasets.ImageFolder(root=f\"{data_dir}/Validation\", transform=transform)\n",
    "test_dataset = datasets.ImageFolder(root=f\"{data_dir}/Test\", transform=transform)\n",
    "\n",
    "# Create DataLoaders\n",
    "batch_size = 32\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# Print dataset sizes\n",
    "print(f\"✅ Training samples: {len(train_dataset)}\")\n",
    "print(f\"✅ Validation samples: {len(val_dataset)}\")\n",
    "print(f\"✅ Test samples: {len(test_dataset)}\")\n",
    "\n",
    "# Check class names\n",
    "print(f\"Classes: {train_dataset.classes}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Projects\\Deepfake\\deepfake_env\\Lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "d:\\Projects\\Deepfake\\deepfake_env\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "Downloading: \"https://download.pytorch.org/models/resnet50-0676ba61.pth\" to C:\\Users\\mahi4/.cache\\torch\\hub\\checkpoints\\resnet50-0676ba61.pth\n",
      "100%|██████████| 97.8M/97.8M [00:09<00:00, 10.5MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ ResNet50 model is ready for fine-tuning on Deepfake dataset!\n"
     ]
    }
   ],
   "source": [
    "#Load and Modify ResNet50 Model\n",
    "\n",
    "import torch\n",
    "import torchvision.models as models\n",
    "import torch.nn as nn\n",
    "\n",
    "# Load the pretrained ResNet50 model\n",
    "resnet50 = models.resnet50(pretrained=True)\n",
    "\n",
    "# Modify the final fully connected layer for binary classification\n",
    "num_ftrs = resnet50.fc.in_features\n",
    "resnet50.fc = nn.Linear(num_ftrs, 2)  # 2 classes: Real & Fake\n",
    "\n",
    "# Move model to GPU if available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "resnet50 = resnet50.to(device)\n",
    "\n",
    "print(\"✅ ResNet50 model is ready for fine-tuning on Deepfake dataset!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Training samples: 140002\n",
      "✅ Validation samples: 39428\n",
      "✅ Test samples: 10905\n",
      "Classes: ['Fake', 'Real']\n"
     ]
    }
   ],
   "source": [
    "#Data Augmentation & DataLoader Setup\n",
    "import torch\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Define data transformations\n",
    "data_transforms = {\n",
    "    \"train\": transforms.Compose([\n",
    "        transforms.Resize((224, 224)),  # Resize to match ResNet50 input\n",
    "        transforms.RandomHorizontalFlip(),  # Augmentation for better learning\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])  # ImageNet normalization\n",
    "    ]),\n",
    "    \"val\": transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    \"test\": transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ])\n",
    "}\n",
    "\n",
    "# Define dataset directory\n",
    "data_dir = \"D:/Projects/Dataset\"\n",
    "\n",
    "# Load datasets\n",
    "datasets_dict = {\n",
    "    \"train\": datasets.ImageFolder(root=f\"{data_dir}/Train\", transform=data_transforms[\"train\"]),\n",
    "    \"val\": datasets.ImageFolder(root=f\"{data_dir}/Validation\", transform=data_transforms[\"val\"]),\n",
    "    \"test\": datasets.ImageFolder(root=f\"{data_dir}/Test\", transform=data_transforms[\"test\"])\n",
    "}\n",
    "\n",
    "# Create DataLoaders\n",
    "batch_size = 32  # Adjust batch size based on available GPU memory\n",
    "dataloaders = {\n",
    "    \"train\": DataLoader(datasets_dict[\"train\"], batch_size=batch_size, shuffle=True, num_workers=4, pin_memory=True),\n",
    "    \"val\": DataLoader(datasets_dict[\"val\"], batch_size=batch_size, shuffle=False, num_workers=4, pin_memory=True),\n",
    "    \"test\": DataLoader(datasets_dict[\"test\"], batch_size=batch_size, shuffle=False, num_workers=4, pin_memory=True)\n",
    "}\n",
    "\n",
    "# Check dataset sizes\n",
    "print(f\"✅ Training samples: {len(datasets_dict['train'])}\")\n",
    "print(f\"✅ Validation samples: {len(datasets_dict['val'])}\")\n",
    "print(f\"✅ Test samples: {len(datasets_dict['test'])}\")\n",
    "print(f\"Classes: {datasets_dict['train'].classes}\")  # Should output ['Fake', 'Real']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Using device: cpu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/resnet50-11ad3fa6.pth\" to C:\\Users\\mahi4/.cache\\torch\\hub\\checkpoints\\resnet50-11ad3fa6.pth\n",
      "100%|██████████| 97.8M/97.8M [00:08<00:00, 11.8MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ ResNet50 model is ready for training on Deepfake dataset!\n"
     ]
    }
   ],
   "source": [
    "#Feature Extraction \n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.models as models\n",
    "\n",
    "# Check if GPU is available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"✅ Using device: {device}\")\n",
    "\n",
    "# Load pretrained ResNet50 model\n",
    "model = models.resnet50(weights=models.ResNet50_Weights.DEFAULT)\n",
    "\n",
    "# Freeze all layers except the final classification layer\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False  # This prevents updating existing weights\n",
    "\n",
    "# Modify the final layer for binary classification (2 classes: Fake, Real)\n",
    "num_ftrs = model.fc.in_features  # Get the number of input features to the final layer\n",
    "model.fc = nn.Linear(num_ftrs, 2)  # Change output layer to 2 classes\n",
    "\n",
    "# Move the model to GPU if available\n",
    "model = model.to(device)\n",
    "\n",
    "print(\"✅ ResNet50 model is ready for training on Deepfake dataset!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision import datasets, models\n",
    "import time\n",
    "\n",
    "# Set device (use GPU if available)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Data transformations\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# Load datasets\n",
    "data_dir = \"D:/Projects/Dataset\"\n",
    "train_dataset = datasets.ImageFolder(root=f\"{data_dir}/Train\", transform=transform)\n",
    "val_dataset = datasets.ImageFolder(root=f\"{data_dir}/Validation\", transform=transform)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "# Load ResNet50 model (pretrained)\n",
    "model = models.resnet50(weights=\"IMAGENET1K_V1\")\n",
    "\n",
    "# Modify the classifier for binary classification (fake/real)\n",
    "num_ftrs = model.fc.in_features\n",
    "model.fc = nn.Linear(num_ftrs, 2)  # 2 classes: Fake & Real\n",
    "\n",
    "# Move model to device\n",
    "model = model.to(device)\n",
    "\n",
    "# Define loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0001)\n",
    "\n",
    "# Training function\n",
    "def train_model(model, train_loader, val_loader, criterion, optimizer, epochs=5):\n",
    "    start_time = time.time()\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        print(f\"Epoch {epoch+1}/{epochs}\")\n",
    "        \n",
    "        # Training phase\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        \n",
    "        for images, labels in train_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            running_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "        train_acc = 100 * correct / total\n",
    "        train_loss = running_loss / len(train_loader)\n",
    "\n",
    "        # Validation phase\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for images, labels in val_loader:\n",
    "                images, labels = images.to(device), labels.to(device)\n",
    "                outputs = model(images)\n",
    "                loss = criterion(outputs, labels)\n",
    "                \n",
    "                val_loss += loss.item()\n",
    "                _, predicted = torch.max(outputs, 1)\n",
    "                total += labels.size(0)\n",
    "                correct += (predicted == labels).sum().item()\n",
    "\n",
    "        val_acc = 100 * correct / total\n",
    "        val_loss = val_loss / len(val_loader)\n",
    "\n",
    "        print(f\"✅ Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.2f}%\")\n",
    "        print(f\"🔹 Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.2f}%\\n\")\n",
    "\n",
    "    end_time = time.time()\n",
    "    print(f\"🎯 Training completed in {(end_time - start_time)/60:.2f} minutes.\")\n",
    "\n",
    "# Start fine-tuning\n",
    "train_model(model, train_loader, val_loader, criterion, optimizer, epochs=5)\n",
    "\n",
    "# Save model\n",
    "torch.save(model.state_dict(), \"deepfake_resnet50.pth\")\n",
    "print(\"✅ Model saved as deepfake_resnet50.pth\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deepfake_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
